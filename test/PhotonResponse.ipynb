{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photon response\n",
    "\n",
    "This notebook builds up on the output of the [HGCDigiTester](https://github.com/PFCal-dev/HGCElectronicsValidation/blob/master/src/HGCDigiTester.cc) tool.\n",
    "The reconstructed hits are aggregated into showers and different levels of corrections are applied to build the energy estimator of the shower:\n",
    "\n",
    "* dE/dx weights\n",
    "* charge collection, light yield and geometry corrections\n",
    "* sums per sensor type and section\n",
    "\n",
    "The summaries just need to be created once as they take a bit of time to process:\n",
    "\n",
    "* In case you need to produce the summaries, please connect first to the k8s spark cluster and set spark.driver.maxResultSize=0 (for unlimited output). Alternatively you can run in multithread locally. It seems to be more efficient for the ntuples of 26/Nov/2020\n",
    "* In case the summaries are already available, one can jump directly to the plotting part of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.20/06\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ROOT\n",
    "import pandas as pd\n",
    "import PyRDF\n",
    "import numpy as np\n",
    "\n",
    "baseDir='/eos/cms/store/cmst3/user/psilva/HGCAL/emResponse'\n",
    "flist=[os.path.join(baseDir,f) for f in os.listdir(baseDir) if '.root' in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the dataframes for analysis\n",
    "\n",
    "This step will take a bit of time as it requires to analyze all the hits and apply the corrections/sums defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/cvmfs/sft.cern.ch/lcg/releases/spark/2.4.5-cern1-f7679/x86_64-centos7-gcc8-opt/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/cvmfs/sft.cern.ch/lcg/releases/hadoop/2.7.5.1-79196/x86_64-centos7-gcc8-opt/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "21/01/13 15:28:58 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "runLocal=True\n",
    "\n",
    "#local\n",
    "if runLocal:\n",
    "    ROOT.ROOT.EnableImplicitMT()\n",
    "    PyRDF.use('local')\n",
    "\n",
    "#spark configuration\n",
    "#cf https://spark.apache.org/docs/latest/configuration#available-properties for details\n",
    "#maxResultSize is set to unlimited however it seems to work only when set to 0 at connection time in the form\n",
    "else:\n",
    "    spark_conf={'npartitions':12,\n",
    "                'spark.driver.maxResultSize':0, \n",
    "                }\n",
    "    PyRDF.use('spark',conf=spark_conf)\n",
    "\n",
    "#include helper header\n",
    "PyRDF.include_headers(\"PhotonResponse_helpers.h\")\n",
    "\n",
    "def getSummaryFrom(url,ran=None):\n",
    "    \n",
    "    \"\"\"convert trees to dataframes and pre-select them for calibration\"\"\"\n",
    "    \n",
    "    print('Starting analysis of',url)\n",
    "    if runLocal:\n",
    "        files=[url]\n",
    "    else:\n",
    "        files = ['root://eosuser.cern.ch/{}'.format(url)]\n",
    "    rdf = PyRDF.RDataFrame(\"ana/hits\", files)\n",
    "    \n",
    "    #filter event range if required\n",
    "    if ran:\n",
    "        rdf=rdf.Filter('event>={} && event<={}'.format(*ran))\n",
    "\n",
    "    #filter the hits (at least 1 simulated MIP deposit)    \n",
    "    rdf=rdf.Filter('mipsim>=1.0')\n",
    "    \n",
    "    #helper variables\n",
    "    rdf=rdf.Define('side','z<0 ? -1 : 1')\n",
    "    for c in ['miprec','avgmiprec']:\n",
    "        new_c='{}_dedx'.format(c)\n",
    "        mpvest='true' if c=='miprec' else 'false'\n",
    "        rdf=rdf.Define(new_c,          'scaledHit(layer,{},cce,true,false)'.format(c)) \\\n",
    "               .Define(new_c+'_cce',   'scaledHit(layer,{},cce,true,true)'.format(c)) \\\n",
    "               .Define(new_c+'_cce_sw','swCompensatedHit({}_cce,thick,isSci,{})'.format(new_c,mpvest))\n",
    "    \n",
    "    #all done\n",
    "    df=pd.DataFrame( rdf.AsNumpy() )\n",
    "    print('\\tFilled with',df.shape[0],'hits to analyze from',len(df['event'].unique()),'events')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over available files\n",
    "rewrite=False\n",
    "for url in flist:\n",
    "    new_url = url.replace('.root','.h5')\n",
    "    if os.path.isfile(new_url) and not rewrite: continue\n",
    "    try:\n",
    "        ran=[0,5000] if 'Flat' in url else None\n",
    "        hits=getSummaryFrom(url,ran=ran)\n",
    "        hits.to_hdf(new_url,key='hits',mode='w')\n",
    "        print(hits[['layer','gvz','gvradius','genergy']].describe())\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the shower energy estimators\n",
    "\n",
    "To sum the total energy per shower we index the data using (event,side), assuming one particle in each endcap, and sum up the different energy estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categs=['CEE_Si120',      'CEE_Si200',       'CEE_Si300',\n",
    "        'CEHfine_Si120',  'CEHfine_Si200',   'CEHfine_Si300',   'CEHfine_Sci',\n",
    "        'CEHcoarse_Si120','CEHcoarse_Si200', 'CEHcoarse_Si300', 'CEHcoarse_Sci',        \n",
    "        'last']\n",
    "\n",
    "def getMaskForCateg(df,categ):\n",
    "\n",
    "    \"\"\"defines a mask for different categories\"\"\"\n",
    "\n",
    "    mask=(df['layer']<=28)\n",
    "    if 'CEHfine' in categ:   mask=(df['layer']>28) & (df['layer']<41)\n",
    "    if 'CEHcoarse' in categ: mask=(df['layer']>40)\n",
    "    if 'last' in categ:      mask=(df['layer']>48)\n",
    "    \n",
    "    if 'Sci' in categ:\n",
    "        mask &= (df['isSci']==1)\n",
    "    elif 'Si' in categ:\n",
    "        if '120' in categ: mask &= (df['thick']==0)\n",
    "        if '200' in categ: mask &= (df['thick']==1)\n",
    "        if '300' in categ: mask &= (df['thick']==2)\n",
    "            \n",
    "    return mask        \n",
    "        \n",
    "def getShowerSummaryForCalibration(df):\n",
    "    \n",
    "    \"\"\"sums up the energy estimators per shower\"\"\"\n",
    "    \n",
    "    #index the showers by event number and side\n",
    "    df_indexed=df.set_index(['event','side'])\n",
    "    level=[0,1]\n",
    "    \n",
    "    #start to describe the contents of the summary\n",
    "    shower_desc = { 'genergy'           : df_indexed.mean(level=level)['genergy'],\n",
    "                    'geta'              : np.abs(df_indexed.mean(level=level)['geta']),\n",
    "                    'gvradius'          : df_indexed.mean(level=level)['gvradius'],\n",
    "                    'gvz'               : df_indexed.mean(level=level)['gvz'],\n",
    "                    'thick'             : df_indexed.mean(level=level)['thick'],\n",
    "                    'isSci'             : df_indexed.mean(level=level)['isSci'],\n",
    "                    'totalSat'          : df_indexed.sum(level=level)['isSat'],\n",
    "                  }\n",
    "\n",
    "    #define the columns with the values ready to be summed for the reconstruction of the energy\n",
    "    for c in ['miprec','avgmiprec']:\n",
    "                \n",
    "        for cat in categs:\n",
    "            mask=getMaskForCateg(df_indexed,cat)\n",
    "\n",
    "            df_indexed['{}_dedx_{}'.format(c,cat)]        = np.where(mask,df_indexed['{}_dedx'.format(c)],0.)\n",
    "            shower_desc['total_{}_dedx_{}'.format(c,cat)] = df_indexed.sum(level=level)['{}_dedx_{}'.format(c,cat)]       \n",
    "\n",
    "            df_indexed['{}_dedx_cce_{}'.format(c,cat)]        = np.where(mask,df_indexed['{}_dedx_cce'.format(c)],0.)\n",
    "            shower_desc['total_{}_dedx_cce_{}'.format(c,cat)] = df_indexed.sum(level=level)['{}_dedx_cce_{}'.format(c,cat)] \n",
    "            \n",
    "            df_indexed['{}_dedx_cce_sw_{}'.format(c,cat)]        = np.where(mask,df_indexed['{}_dedx_cce_sw'.format(c)],0.)\n",
    "            shower_desc['total_{}_dedx_cce_sw_{}'.format(c,cat)] = df_indexed.sum(level=level)['{}_dedx_cce_sw_{}'.format(c,cat)] \n",
    "            \n",
    "        shower_desc['total_{}_dedx'.format(c)] = df_indexed.sum(level=level)['{}_dedx'.format(c)]       \n",
    "        shower_desc['total_{}_dedx_cce'.format(c)] = df_indexed.sum(level=level)['{}_dedx_cce'.format(c)] \n",
    "        shower_desc['total_{}_dedx_cce_sw'.format(c)] = df_indexed.sum(level=level)['{}_dedx_cce_sw'.format(c)] \n",
    "            \n",
    "    #build the shower summary and filter in case there are saturated hits\n",
    "    shower_data = pd.DataFrame(shower_desc)\n",
    "    mask = (shower_data['totalSat']==0)\n",
    "    shower_data=shower_data[mask]\n",
    "    shower_data.drop(columns=['totalSat'],inplace=True)\n",
    "    shower_data.reset_index(inplace=True)\n",
    "\n",
    "    return shower_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with /eos/cms/store/cmst3/user/psilva/HGCAL/emResponse/FlatRandomPtGunProducer_16x_vanilla_20201112.h5\n",
      "\tLimiting to 5k events (10k photons)\n",
      "\tLayers in range 1 50\n"
     ]
    }
   ],
   "source": [
    "#loop over the hit summaries\n",
    "hit_flist=[os.path.join(baseDir,f) for f in os.listdir(baseDir) if '.h5' in f]\n",
    "for url in hit_flist:\n",
    "    \n",
    "    if not 'Flat' in url: continue\n",
    "    \n",
    "    print('Starting with',url)\n",
    "    \n",
    "    #get hits and build the shower data summary\n",
    "    df = pd.read_hdf(url,key='hits',mode='a')\n",
    "    if 'Flat' in url:\n",
    "        print('\\tLimiting to 5k events (10k photons)')\n",
    "        df=df[df['event']<5000]\n",
    "    \n",
    "    try:\n",
    "        showers_df=pd.read_hdf(url,key='showers',mode='a')\n",
    "        print(showers_df.shape)\n",
    "        print('Shower summaries already available, moving to next')     \n",
    "        continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print('\\tLayers in range',df['layer'].min(),df['layer'].max())\n",
    "    \n",
    "    showers_df = getShowerSummaryForCalibration(df)\n",
    "    print('\\tSelected',showers_df.shape[0],'showers for calibration')\n",
    "\n",
    "    showers_df.to_hdf(url,key='showers',mode='a')\n",
    "    print('\\tSummary @',url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 14\n",
    "\n",
    "sampleTitles={'CloseByParticleGunProducer_16x_vanilla_20201114.h5'      : 'Non-pointing $\\gamma$ vanilla',\n",
    "              'CloseByParticleGunProducer_aged3iab_20201117.h5'         : 'Non-pointing $\\gamma$ 3ab$^{-1}$',\n",
    "              'CloseByParticleGunProducer_realisticStartup_20201123.h5' : 'Non-pointing $\\gamma$ realistic startup',\n",
    "              'CloseByParticleGunProducer_aged3iab_20201127.h5'         : 'Non-pointing $\\gamma$, 3ab$^{-1}$',\n",
    "              'CloseByParticleGunProducer_realisticStartup_20201127.h5' : 'Non-pointing $\\gamma$, realistic startup',\n",
    "              'FlatRandomPtGunProducer_16x_vanilla_20201112.h5'         : 'Pointing $\\gamma$ vanilla',\n",
    "              'FlatRandomPtGunProducer_aged3iab_20201022.h5'            : 'Pointing $\\gamma$ 3ab$^{-1}$',\n",
    "              'FlatRandomPtGunProducer_aged3iab_20201023.h5'            : 'Pointing $\\gamma$ 3ab$^{-1}$',\n",
    "              'FlatRandomPtGunProducer_realisticStartup_20201110.h5'    : 'Pointing $\\gamma$ realistic startup',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearity between injected and reconstructed charge\n",
    "\n",
    "Plots the sim vs rec charge and the distribution of the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[f for f in os.listdir(baseDir) if '.h5' in f]\n",
    "resp_bins=np.linspace(0.5,1.5,100)\n",
    "for f in files:\n",
    "    url=os.path.join(baseDir,f)\n",
    "    if not f in sampleTitles.keys(): continue\n",
    "    df=pd.read_hdf(url,key='hits').iloc[:100000] #no need to use all of them for this check\n",
    "    \n",
    "    nrows=4 if 'CloseByParticleGun' in f else 3\n",
    "    fig,ax=plt.subplots(1,nrows,figsize=(nrows*5.5,5))\n",
    "    fig2,ax2=plt.subplots(1,nrows,figsize=(nrows*5.5,5))\n",
    "\n",
    "    i=0\n",
    "    for title,mask in [(r'120 $\\mu$m',(df['thick']==0) & (df['isSat']==0)),\n",
    "                       (r'200 $\\mu$m',(df['thick']==1) & (df['isSat']==0)),\n",
    "                       (r'300 $\\mu$m',(df['thick']==2) & (df['isSat']==0)),\n",
    "                       ('Scintillator',(df['isSci']==1) & (df['isSat']==0))]:         \n",
    "\n",
    "        ax[i].scatter(df[mask]['mipsim'],df[mask]['miprec'],label='before CCE')\n",
    "        ax[i].scatter(df[mask]['mipsim'],df[mask]['miprec']/df[mask]['cce'],label='after CCE')\n",
    "        ax[i].set_xlabel('Sim MIPs')\n",
    "        ax[i].legend(loc='upper left',title=title)\n",
    "        ax[i].grid()\n",
    "        \n",
    "        ax2[i].hist(df[mask]['miprec']/df[mask]['mipsim'],histtype='step',linewidth=2,bins=resp_bins,label='before corr.')\n",
    "        ax2[i].hist( (df[mask]['miprec']/df[mask]['cce'])/df[mask]['mipsim'],histtype='step',linewidth=2,bins=resp_bins,label='after corr.')\n",
    "        mask &= (df['isTOT']==1)\n",
    "        ax2[i].hist( (df[mask]['miprec']/df[mask]['cce'])/df[mask]['mipsim'],histtype='step',linewidth=2,bins=resp_bins,label='after corr. (TOT)')\n",
    "    \n",
    "        ax2[i].set_xlabel('Rec/Sim')\n",
    "        ax2[i].legend(loc='upper left',title=title)\n",
    "        ax2[i].grid()\n",
    "\n",
    "        if i==0:\n",
    "            ax[i].set_ylabel('Rec MIPs')\n",
    "            ax2[i].set_ylabel('Hits')\n",
    "            ax[i].text(0.05,1.05,r'CMS Simulation {}'.format(sampleTitles[f]),transform=ax[i].transAxes,fontsize=16)\n",
    "            ax2[i].text(0.05,1.05,r'CMS Simulation {}'.format(sampleTitles[f]),transform=ax2[i].transAxes,fontsize=16)\n",
    "\n",
    "        i=i+1\n",
    "        if i>nrows-1 : break \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical energy spectrum from the simulated hits\n",
    "\n",
    "Distribution of charge in the pads generated by photons originated from (0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_hdf('/eos/cms/store/cmst3/user/psilva/HGCAL/emResponse/FlatRandomPtGunProducer_16x_vanilla_20201112.h5',key='hits')\n",
    "\n",
    "mask=(df['thick']==2)\n",
    "mipsim=df[mask]['mipsim']\n",
    "gpt=df[mask]['genergy']/np.cosh(df[mask]['geta'])\n",
    "mipfC=3.6087\n",
    "\n",
    "bins=np.percentile(mipsim,[x*5 for x in range(21)], axis=0)\n",
    "sel_p=[10,50,90]\n",
    "sel_quantiles=np.percentile(mipsim,sel_p, axis=0)\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_ylabel(r'dN$_{hits}$/dMIPs')\n",
    "ax1.set_xlabel(r'MIPs')\n",
    "ax1.set_xscale('log')\n",
    "ax1.hist(mipsim,         bins=bins, density=True, histtype='step', lw=2, label=r'10<p$_{T}$<100 GeV')\n",
    "ax1.hist(mipsim[gpt<20], bins=bins, density=True, histtype='step', lw=2, label=r'p$_{T}$<25 GeV')\n",
    "ax1.hist(mipsim[gpt>90], bins=bins, density=True, histtype='step', lw=2, label=r'p$_{T}$>90 GeV')\n",
    "ax1.legend()\n",
    "ax1.set_yscale('log')\n",
    "for i in range(3):\n",
    "    ax1.plot([sel_quantiles[i],sel_quantiles[i]],[0,0.2],ls='--',color='gray')\n",
    "    print('quantile ',sel_p[i],':',sel_quantiles[i],'MIPs = ',sel_quantiles[i]*mipfC,'fC')\n",
    "\n",
    "ax1.grid()\n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "ax2.set_xscale('log')\n",
    "new_tick_locations = np.array([1/mipfC,5/mipfC,10/mipfC,50/mipfC,100/mipfC,500/mipfC,1000/mipfC])\n",
    "def tick_function(X):\n",
    "    V = X*mipfC\n",
    "    return [\"%.0f\" % z for z in V]\n",
    "ax2.set_xlim(ax1.get_xlim())\n",
    "ax2.set_xticks(new_tick_locations)\n",
    "ax2.set_xticklabels(tick_function(new_tick_locations))\n",
    "ax2.set_xlabel(r\"q [fC]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photon energy response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varTitles={'geta':'|\\eta|',\n",
    "           'gvz' : 'Vertex~z~[cm]',\n",
    "           'gvradius' : 'Vertex~radius~[cm]',\n",
    "           'genergy':'E_{gen}/GeV'}\n",
    "\n",
    "def showResponseProfile(summary,\n",
    "                        en_est=['total_miprec_dedx','total_miprec_dedx_cce'],\n",
    "                        en_est_label=['dE/dx','dE/dx+corr.'],\n",
    "                        en_est_fit=[False,True],\n",
    "                        xvar='geta',\n",
    "                        ytitle='Reconstructed/Generated',\n",
    "                        title='',\n",
    "                        yran=None):\n",
    "    \n",
    "    fig,ax=plt.subplots(figsize=(6,5))\n",
    "    \n",
    "    x = abs(summary[xvar])\n",
    "    xvar_title=varTitles[xvar]\n",
    "    for i,iy in enumerate(en_est):\n",
    "        \n",
    "        y = 1e-3*summary[iy]/summary['genergy']\n",
    "        plt.scatter(x,y,label=en_est_label[i])\n",
    "\n",
    "        #fit the average reponse if required\n",
    "        if not en_est_fit[i]: continue\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        yexp = slope*x+intercept\n",
    "        plt.plot(x,yexp,'r',label=r'R={:3.4f}$\\cdot {}$+{:3.3f}'.format(slope,xvar_title,intercept))\n",
    "    \n",
    "    plt.xlabel(r'${}$'.format(xvar_title))\n",
    "    plt.ylabel(ytitle)\n",
    "    if yran: plt.ylim(*yran)\n",
    "    plt.grid()\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.text(0.05,1.05,r'CMS Simulation {}'.format(title),transform=ax.transAxes,fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()   \n",
    "\n",
    "\n",
    "def showResponseByThickness(summary,\n",
    "                            en_est='total_miprec_dedx_cce',\n",
    "                            xtitle='Reconstructed/Generated',\n",
    "                            title='',\n",
    "                            xran=(1.0,1.4)):\n",
    "    \n",
    "    fig,ax=plt.subplots(figsize=(6,5))\n",
    "    bins=np.linspace(xran[0],xran[1],50)\n",
    "    for label,mask in [('120$\\mu$m',abs(summary['thick']-0)<0.01),\n",
    "                       ('200$\\mu$m',abs(summary['thick']-1)<0.01),\n",
    "                       ('300$\\mu$m',abs(summary['thick']-2)<0.01),\n",
    "                      ]:\n",
    "\n",
    "        x = 1e-3*summary[mask][en_est]/summary[mask]['genergy']\n",
    "        plt.hist(x,bins=bins,label=label,histtype='step',linewidth=2)\n",
    "    plt.xlabel(xtitle)\n",
    "    plt.grid()\n",
    "    plt.legend(loc='best')\n",
    "    plt.text(0.05,1.05,r'CMS Simulation {}'.format(title),transform=ax.transAxes,fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sample in ['FlatRandomPtGunProducer_aged3iab_20201022.h5',\n",
    "               #'FlatRandomPtGunProducer_aged3iab_20201023.h5',\n",
    "               #'FlatRandomPtGunProducer_realisticStartup_20201110.h5', \n",
    "              ]:\n",
    "    \n",
    "    df=pd.read_hdf(os.path.join(baseDir,sample),key='showers')\n",
    "    df=df[(df['geta']>1.6) & (df['geta']<2.9)]\n",
    "\n",
    "    #showResponseProfile(df,title=sampleTitles[sample],xvar='gvz')\n",
    "    #showResponseByThickness(df,en_est='total_miprec_dedx_cce',title=sampleTitles[sample])\n",
    "\n",
    "    #showResponseProfile(df,en_est=['total_avgmiprec_dedx','total_avgmiprec_dedx_cce'],title=sampleTitles[sample])\n",
    "    #showResponseByThickness(df,en_est='total_avgmiprec_dedx_cce',title=sampleTitles[sample],xran=(0.6,1.0))\n",
    "    \n",
    "    showResponseProfile(df,en_est=['total_avgmiprec_dedx','total_avgmiprec_dedx_cce_sw'],title=sampleTitles[sample])\n",
    "    showResponseByThickness(df,en_est='total_avgmiprec_dedx_cce_sw',title=sampleTitles[sample],xran=(0.6,1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local e.m. corrections\n",
    "We correct the residual difference in response for the three thicknesses by minimizing $E = \\sum_{i \\in \\{120,200,300\\} } E_i w_i$. The CCE correction is also applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HGCAL envelope comes from here https://edms.cern.ch/ui/#!master/navigator/document?P:1467919020:100561389:subDocs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "hgcal_envelope_pts=0.1*np.array([[2965,260.0],[2965,1243.7],[3185,1364.7],[3185,1589.4],[3837.0,1816],[4522.0,2725],[5265,2725],[5265,900],[5265,900],[5265,360.0],[4430,360.0],[4430,260.0],[2965,260.0]])\n",
    "hgcal_envelope = Path(hgcal_envelope_pts)\n",
    "\n",
    "rm=2*30\n",
    "hgcal_fid_pts=0.1*np.array([[2965,260.0+rm],[2965,1243.7-rm],[3185,1364.7-rm],[3185,1589.4-rm],[3837.0,1816-rm],[4522.0,2725-rm],[5265,2725-rm],\n",
    "                            [5265,900+rm],[5265,900+rm],[5265,360.0+rm],[4430,360.0+rm],[4430,260.0+rm],[2965,260.0+rm]])\n",
    "hgcal_fid = Path(hgcal_fid_pts)\n",
    "\n",
    "\n",
    "def showHGCALEnvelope(pts=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    patch = patches.PathPatch(hgcal_envelope, facecolor='orange', alpha=0.25, lw=3)\n",
    "    ax.add_patch(patch)\n",
    "    if not pts is None:\n",
    "        ax.scatter(pts[:,0],pts[:,1])\n",
    "    ax.set_xlim(250, 600)\n",
    "    ax.set_ylim(0, 300)\n",
    "    ax.set_xlabel('z [cm]')\n",
    "    ax.set_ylabel('r [cm]')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    " \n",
    "#CMSSW acceptance https://hgcal.web.cern.ch/HitCalibration/WorkingExample/\n",
    "pts=np.array([[321,55],[321,90],[321,135],[430,80],[430,180],[362.52,50],[362.52,90],[362.52,135.0]])\n",
    "showHGCALEnvelope(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "categs=['CEE_Si120',      'CEE_Si200',       'CEE_Si300',\n",
    "        'CEHfine_Si120',  'CEHfine_Si200',   'CEHfine_Si300',   'CEHfine_Sci',\n",
    "        'CEHcoarse_Si120','CEHcoarse_Si200', 'CEHcoarse_Si300', 'CEHcoarse_Sci']\n",
    "\n",
    "def selectForCalibration(sample,enest,pointing=False,silent=False):\n",
    "    #open file\n",
    "    url=os.path.join(baseDir,sample)\n",
    "    df=pd.read_hdf(url,key='showers')\n",
    "\n",
    "    #no leakage\n",
    "    leak_mask=~(df['total_{}_dedx_cce_last'.format(enest)]/df['total_{}_dedx_cce'.format(enest)]>0.01)\n",
    "    df=df[leak_mask]\n",
    "    \n",
    "    #hgcal fiducial pointing / non-pointing\n",
    "    if pointing:\n",
    "        mask=(df['geta']>1.6) & (df['geta']<2.9)\n",
    "        df=df[mask]\n",
    "    else:\n",
    "        zr_pts=df[['gvz','gvradius']].to_numpy()\n",
    "        mask=hgcal_fid.contains_points(zr_pts)\n",
    "        df=df[mask]\n",
    "        zr_pts=df[['gvz','gvradius']].to_numpy()\n",
    "        if not silent:\n",
    "            showHGCALEnvelope(zr_pts)\n",
    "\n",
    "    return df\n",
    "    \n",
    "def runLocalEMRegression(sample,enest='miprec'):\n",
    "\n",
    "    df=selectForCalibration(sample,enest)\n",
    "    \n",
    "    Esums=['total_{}_dedx_cce_{}'.format(enest,c) for c in categs]\n",
    "    X = df[Esums]\n",
    "    y = df['genergy']\n",
    "    print(y.min(),y.max())\n",
    "\n",
    "    #ordinary least square method https://www.statsmodels.org/stable/generated/statsmodels.regression.linear_model.OLS.html\n",
    "    ols     = sm.OLS(y, X)\n",
    "    results = ols.fit()\n",
    "\n",
    "    new_enest='total_{}_dedx_cce_localem'.format(enest)\n",
    "    df[new_enest]=1e3*results.predict() #keep in MeV\n",
    "\n",
    "    print('Linear regression results')\n",
    "    print(r'Accuracy (R^2):',results.rsquared)\n",
    "    for ip in range(len(results.params)):\n",
    "        print('{:15s} {:3.3f} +/- {:3.3f}'.format(categs[ip],1e3*results.params[ip],1e3*results.bse[ip]))\n",
    "\n",
    "    for xvar in ['gvz','gvradius','genergy']:\n",
    "        showResponseProfile(df,\n",
    "                            en_est=['total_{}_dedx'.format(enest),new_enest],\n",
    "                            title=sampleTitles[sample],\n",
    "                            xvar=xvar)\n",
    "\n",
    "    return results\n",
    "    \n",
    "enest='avgmiprec'\n",
    "#tag='CloseByParticleGunProducer_16x_vanilla_20201114.h5'\n",
    "tag='CloseByParticleGunProducer_realisticStartup_20201127.h5'\n",
    "emlocalcorr=runLocalEMRegression(tag,enest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sample in sampleTitles:\n",
    "\n",
    "    df=selectForCalibration(sample,enest,pointing=True if 'Flat' in sample else False)\n",
    "    Esums=['total_{}_dedx_cce_{}'.format(enest,c) for c in categs]\n",
    "    X = df[Esums]\n",
    "    y = df['genergy']\n",
    "    \n",
    "    new_enest='total_{}_dedx_cce_localem'.format(enest)\n",
    "    df[new_enest]=1e3*emlocalcorr.predict(X) #keep in MeV\n",
    "\n",
    "    showResponseProfile(df,\n",
    "                        en_est=['total_{}_dedx'.format(enest),new_enest],\n",
    "                        title=sampleTitles[sample],\n",
    "                        xvar='gvradius',\n",
    "#                        xvar='genergy' if 'CloseBy' in sample else 'geta',\n",
    "                        yran=(0.4,1.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy resolution maps\n",
    "\n",
    "We divide a sample in equal statistics in z and for each z in energy. For each category the effective resolution and the bias is computed.\n",
    "The results are interpolated creating a smooth map of the e.m. resolution in HGCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCentralAndUncertainty(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    estimates the median and the quantiles for a 68%CI around it\n",
    "    returns the median, median uncertainty, effective width and the unc. on eff. width\n",
    "    the uncertainties are compued using a gaussian approximation\n",
    "    (a la ROOT https://root.cern.ch/doc/master/TH1_8cxx_source.html#l07467)\n",
    "    \"\"\"\n",
    "    \n",
    "    p=np.percentile(x, [16,50,84])\n",
    "    sigma=np.std(x,axis=0)\n",
    "    n=x.shape[0]\n",
    "    \n",
    "    #median and uncertainty on median\n",
    "    r=p[1]\n",
    "    unc_r=1.253*sigma/np.sqrt(n)\n",
    "    \n",
    "    #eff. width and uncertainty on it \n",
    "    wid_r=0.5*(p[2]-p[0])\n",
    "    unc_wid_r=sigma/np.sqrt(2*n)\n",
    "    \n",
    "    return [r,unc_r,wid_r,unc_wid_r]\n",
    "\n",
    "def buildCalibrationSummary(sample,enest,xvar='gvz',yvar='genergy',pointing=False):\n",
    "    \"\"\"\n",
    "    slices the data in two variables ensuring equal statistics in each category\n",
    "    then computes the bias and the resolution in each category\n",
    "    returns an array of (x,ex,y,ey,bias,ebias,resol,eresol)\n",
    "    \"\"\"\n",
    "\n",
    "    #prepare the sample and evaluate the energy estimator\n",
    "    df=selectForCalibration(sample,enest,silent=True,pointing=pointing)    \n",
    "    Esums=['total_{}_dedx_cce_{}'.format(enest,c) for c in categs]\n",
    "    X = df[Esums]\n",
    "    y = df['genergy']\n",
    "    new_enest='total_{}_dedx_cce_localem'.format(enest)\n",
    "    df[new_enest]=1e3*emlocalcorr.predict(X) #keep in MeV\n",
    "    \n",
    "    #summarize the bias/resolution in different bins\n",
    "    calibSummary=[]\n",
    "    xbins=np.percentile(df[xvar], np.linspace(0,100,10))\n",
    "    for i in range(len(xbins)-1):\n",
    "\n",
    "        xmask=(df[xvar]>=xbins[i]) & (df[xvar]<xbins[i+1])        \n",
    "        ybins=np.percentile(df[xmask][yvar],np.linspace(0,100,15))\n",
    "        for j in range(len(ybins)-1):\n",
    "        \n",
    "            ymask=(df[xmask][yvar]>=ybins[j]) & (df[xmask][yvar]<ybins[j+1])\n",
    "            residuals=df[xmask & ymask][new_enest]/1000.-df[xmask & ymask]['genergy']\n",
    "            calibSummary.append( [i,j,pointing]\n",
    "                                 +getCentralAndUncertainty(df[xmask & ymask][xvar])\n",
    "                                 +getCentralAndUncertainty(df[xmask & ymask][yvar])\n",
    "                                 +getCentralAndUncertainty(residuals)\n",
    "                                 )\n",
    "            \n",
    "    return pd.DataFrame(calibSummary,\n",
    "                        columns=['ix','ij','pointing','x','ex','sx','esx','y','ey','sy','esy','r','er','s','es'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibSummaries=[]\n",
    "i=0\n",
    "for sample in sampleTitles:\n",
    "    print('Building calibration summary for',sample)\n",
    "    \n",
    "    pointing=True if 'Flat' in sample else False\n",
    "    xvar='geta' if pointing else 'gvz'\n",
    "    calibSummaries.append( buildCalibrationSummary(sample,enest,xvar=xvar,pointing=pointing) )\n",
    "    calibSummaries[-1]['sample']=i\n",
    "    i+=1\n",
    "    \n",
    "calibSummaries=pd.concat(calibSummaries)\n",
    "fout=os.path.join(baseDir,'calibration.h5')    \n",
    "calibSummaries.to_hdf(fout,key='calibration',mode='w')\n",
    "calibSummaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for sample in sampleTitles:\n",
    "    print(i,sample)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSummaryResidualsAndResolution(df,title):\n",
    "    \n",
    "    fig,ax=plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "    for ix in sorted(df['ix'].unique()):\n",
    "        mask=(df['ix']==ix)        \n",
    "        x=df[mask]['y']\n",
    "        xerr=df[mask]['ey']\n",
    "\n",
    "        y=df[mask]['r']/x\n",
    "        yerr=df[mask]['er']/x                 \n",
    "        ax[0].errorbar(x,y,yerr,xerr,marker='s',ms=10,ls='None',label='<z>={:3.0f} cm'.format(df[mask]['x'].mean()))\n",
    "\n",
    "        y=df[mask]['s']/x\n",
    "        yerr=df[mask]['es']/x                 \n",
    "        ax[1].errorbar(x,y,yerr,xerr,marker='s',ms=10,ls='None')\n",
    "    \n",
    "    for i in range(2):\n",
    "        ax[i].grid()\n",
    "        ax[i].set_xlabel('E [GeV]',fontsize=16)\n",
    "\n",
    "    ax[0].legend(ncol=2)\n",
    "    ax[0].text(0.01,1.05,r'CMS Simulation {}'.format(title),transform=ax[0].transAxes,fontsize=16)\n",
    "    ax[0].set_ylim(-0.08,0.08)\n",
    "    ax[1].set_ylim(0,0.22)\n",
    "    ax[0].set_ylabel(r'$\\Delta E/E$',fontsize=16)\n",
    "    ax[1].set_ylabel(r'$\\sigma_E/E$',fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "fout=os.path.join(baseDir,'calibration.h5') \n",
    "df=pd.read_hdf(fout,key='calibration')\n",
    "\n",
    "aged=df[df['sample']==3]\n",
    "showSummaryResidualsAndResolution(aged,sampleTitles['CloseByParticleGunProducer_aged3iab_20201127.h5'])\n",
    "\n",
    "realistic=df[df['sample']==4]\n",
    "showSummaryResidualsAndResolution(realistic,sampleTitles['CloseByParticleGunProducer_realisticStartup_20201127.h5'])                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def resol_func(x, a, b, c):\n",
    "    return np.sqrt((a/np.sqrt(x))**2+(b/x)**2+c**2)\n",
    "\n",
    "def compareResolutions(dfList,titleList):\n",
    "\n",
    "        fig,ax=plt.subplots(figsize=(6,5))\n",
    "        fit_results=[]\n",
    "        \n",
    "        for i,df in enumerate(dfList):\n",
    "   \n",
    "            x=df['y']\n",
    "            xerr=df['ey']\n",
    "            bias=df['r']\n",
    "            y=df['s']/(x+bias)\n",
    "            yerr=df['es']/(x+bias)                 \n",
    "            xlin=np.linspace(x.min(),x.max(),100)\n",
    "                            \n",
    "            if i==0:\n",
    "                popt,pcov = curve_fit(lambda x, a,c: resol_func(x, a,0,c),  x, y, sigma=yerr, bounds=[(0.15,0),(0.3,0.05)])\n",
    "                params=r'$\\frac{%3.3f \\pm %3.3f}{\\sqrt{E}}\\oplus'%(popt[0],np.sqrt(pcov[0][0]))\n",
    "                params+=r'%3.3f \\pm %3.3f$'%(popt[1],np.sqrt(pcov[1][1]))                \n",
    "                ax.plot(xlin,resol_func(xlin,popt[0],0.,popt[1]),'b-')\n",
    "                ax.errorbar(x,y,yerr,xerr,marker='s',ms=10,ls='None',label='%s\\n%s'%(titleList[i],params),color='b')\n",
    "            else:\n",
    "                continue\n",
    "                popt,pcov = curve_fit(resol_func, x, y, sigma=yerr, bounds=[(0.1,0.,0.),(0.3,0.5,0.05)])\n",
    "                params=r'$\\frac{%3.3f \\pm %3.3f}{\\sqrt{E}}\\oplus'%(popt[0],np.sqrt(pcov[0][0]))\n",
    "                params+=r'\\frac{%3.3f \\pm %3.3f}{E}\\oplus'%(popt[1],np.sqrt(pcov[1][1]))\n",
    "                params+=r'%3.3f \\pm %3.3f$'%(popt[2],np.sqrt(pcov[2][2]))                \n",
    "                ax.plot(xlin,resol_func(xlin,*popt),'r-')\n",
    "                ax.errorbar(x,y,yerr,xerr,marker='s',ms=10,ls='None',label='%s\\n%s'%(titleList[i],params),color='r')\n",
    "\n",
    "            fit_results.append( [popt,pcov])\n",
    "        \n",
    "        ax.set_xlabel('E [GeV]',fontsize=14)\n",
    "        ax.set_ylabel(r'$\\sigma_E~/~E$  [GeV]',fontsize=14)\n",
    "        ax.text(0.01,1.05,r'CMS Simulation',transform=ax.transAxes,fontsize=16)\n",
    "        plt.legend(fontsize=12)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        \n",
    "compareResolutions([realistic[(realistic['ix']==0) & ((realistic['y']<26) | (realistic['y']>40))],\n",
    "                    aged[(aged['ix']==0)& ((aged['y']<26) | (aged['y']>40))] ],\n",
    "                   [sampleTitles['CloseByParticleGunProducer_realisticStartup_20201127.h5'],sampleTitles['CloseByParticleGunProducer_aged3iab_20201127.h5']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "sparkconnect": {
   "bundled_options": [],
   "list_of_options": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
